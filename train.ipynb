{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d59dd5-a224-4e42-a5c9-8a83fc079bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import reduction\n",
    "import time\n",
    "import datetime\n",
    "import logging\n",
    "import torch\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from tqdm import tqdm_notebook\n",
    "from tools.utils import AverageMeter\n",
    "\n",
    "scaler = torch.amp.GradScaler(init_scale=4096) \n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "def fit_train(config, epoch, model, model2, classifier, clothes_classifier, clothes_classifier2, fuse, criterion_cla, criterion_pair,\n",
    "    criterion_clothes, criterion_adv, optimizer, optimizer2, optimizer_cc, trainloader, pid2clothes, kl):\n",
    "    logger = logging.getLogger('reid.train')\n",
    "    batch_cla_loss = AverageMeter()\n",
    "    batch_pair_loss = AverageMeter()\n",
    "    batch_clo_loss = AverageMeter()\n",
    "    batch_adv_loss = AverageMeter()\n",
    "    batch_clothes_loss2 = AverageMeter()\n",
    "    batch_loss2 = AverageMeter()\n",
    "    batch_jsd_loss = AverageMeter()\n",
    "    corrects = AverageMeter()\n",
    "    corrects2 = AverageMeter()\n",
    "    corrects3 = AverageMeter()\n",
    "    clothes_corrects = AverageMeter()\n",
    "    clothes_corrects2 = AverageMeter()\n",
    "    batch_time = AverageMeter() \n",
    "    data_time = AverageMeter() \n",
    "\n",
    "    model.train()                 \n",
    "    model2.train()                \n",
    "    fuse.train()                  \n",
    "    classifier.train()            \n",
    "    clothes_classifier.train()   \n",
    "    clothes_classifier2.train()   \n",
    "\n",
    "    end = time.time()\n",
    "    for batch_idx, (imgs, pids, camids, clothes_ids, img_path) in enumerate(tqdm_notebook(trainloader)):\n",
    "        # Get all positive clothes classes (belonging to the same identity) for each sample             \n",
    "        pid2clothes = pid2clothes.to(device) \n",
    "        pos_mask = pid2clothes[pids]\n",
    "        imgs, pids, clothes_ids, pos_mask = imgs.to(device), pids.to(device), clothes_ids.to(device), pos_mask.float().to(device)\n",
    "        # Measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "        # Forward pass under AMP \n",
    "        with torch.amp.autocast('cuda', dtype=torch.float16):\n",
    "            pri_feat, features = model(imgs)\n",
    "            pri_feat2, features2 = model2(imgs) \n",
    "                                    \n",
    "            pri_feat2 = pri_feat2.clone().detach()  \n",
    "            features_fuse = fuse(pri_feat, pri_feat2) \n",
    "\n",
    "            features_fuse2 = fuse(pri_feat2, pri_feat) \n",
    "\n",
    "            outputs = classifier(features)  \n",
    "            outputs2 = clothes_classifier2(features2)   \n",
    "            outputs3 = classifier(features_fuse) \n",
    "\n",
    "            outputs4 = clothes_classifier2(features_fuse2.detach()) \n",
    "\n",
    "            pred_clothes = clothes_classifier(features.detach()) \n",
    "\n",
    "            _, preds = torch.max(outputs.data, 1)\n",
    "            _, preds3 = torch.max(outputs3.data, 1)\n",
    "\n",
    "            _, preds4 = torch.max(outputs4.data, 1) \n",
    "        \n",
    "            clothes_loss = criterion_clothes(pred_clothes, clothes_ids)         \n",
    "\n",
    "            new_pred_clothes = clothes_classifier(features)\n",
    "            _, clothes_preds = torch.max(new_pred_clothes.data, 1)  \n",
    "\n",
    "            _, pred_clothes2 = torch.max(outputs2.data, 1)\n",
    "            outputs2_no_grad = clothes_classifier2(features2.detach())\n",
    "\n",
    "            Q = new_pred_clothes.clone().detach() \n",
    "            P = outputs2.clone()                  \n",
    "            Q = torch.nn.functional.softmax(Q, dim=-1)  \n",
    "            P = torch.nn.functional.softmax(P, dim=-1) \n",
    "\n",
    "            clothes_loss2 = criterion_clothes(outputs2, clothes_ids)\n",
    "            \n",
    "            # Calculate the mean distribution M\n",
    "            M = 0.5 * (P + Q)\n",
    "\n",
    "            # Calculate the JSD (average of two KL divergences)\n",
    "            kl_pm = kl(P.log(), M, reduction='sum')  \n",
    "            kl_qm = kl(Q.log(), M, reduction='sum')  \n",
    "\n",
    "            jsd_loss = 0.5 * (kl_pm + kl_qm)\n",
    "            \n",
    "            if epoch >= config.TRAIN.START_EPOCH_CC:\n",
    "                loss2 = clothes_loss2 + config.k_jsl * jsd_loss + config.k_cal * criterion_clothes(outputs2_no_grad - outputs4, clothes_ids) \n",
    "            else:\n",
    "                loss2 = clothes_loss2\n",
    "\n",
    "            GENERAL_EPOCH = config.TRAIN.START_EPOCH_ADV    \n",
    "\n",
    "            # Compute loss\n",
    "            if epoch >= GENERAL_EPOCH:   \n",
    "                cla_loss = criterion_cla(outputs, pids) + config.k_cal * criterion_cla(outputs - outputs3, pids) \n",
    "            else:                                            \n",
    "                cla_loss = criterion_cla(outputs, pids)\n",
    "            pair_loss = criterion_pair(features, pids) \n",
    "            adv_loss = criterion_adv(new_pred_clothes, clothes_ids, pos_mask)  \n",
    "\n",
    "            if epoch >= config.TRAIN.START_EPOCH_ADV:      \n",
    "                loss = cla_loss + adv_loss + config.LOSS.PAIR_LOSS_WEIGHT * pair_loss \n",
    "            else:\n",
    "                loss = cla_loss + config.LOSS.PAIR_LOSS_WEIGHT * pair_loss\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        scaler.scale(loss).backward()\n",
    "\n",
    "        scaler.unscale_(optimizer)\n",
    "        torch.nn.utils.clip_grad_norm_([param for group in optimizer.param_groups for param in group['params']], max_norm=1.0)\n",
    "        \n",
    "        scaler.step(optimizer)\n",
    "\n",
    "        optimizer2.zero_grad()\n",
    "        scaler.scale(loss2).backward()\n",
    "        \n",
    "        scaler.unscale_(optimizer2)\n",
    "        torch.nn.utils.clip_grad_norm_([param for group in optimizer2.param_groups for param in group['params']], max_norm=1.0)\n",
    "\n",
    "        scaler.step(optimizer2)\n",
    "\n",
    "        if epoch >= config.TRAIN.START_EPOCH_CC:   \n",
    "            optimizer_cc.zero_grad()\n",
    "            scaler.scale(clothes_loss).backward()\n",
    "\n",
    "            scaler.unscale_(optimizer_cc)\n",
    "            torch.nn.utils.clip_grad_norm_([param for group in optimizer_cc.param_groups for param in group['params']], max_norm=1.0)\n",
    "            \n",
    "            scaler.step(optimizer_cc)\n",
    "\n",
    "        scaler.update()\n",
    "        \n",
    "\n",
    "        # statistics\n",
    "        corrects.update(torch.sum(preds == pids.data).float()/pids.size(0), pids.size(0))\n",
    "        corrects2.update(torch.sum(pred_clothes2 == clothes_ids.data).float()/clothes_ids.size(0), clothes_ids.size(0))\n",
    "        corrects3.update(torch.sum(preds3 == pids.data).float()/pids.size(0), pids.size(0))\n",
    "        clothes_corrects.update(torch.sum(clothes_preds == clothes_ids.data).float()/clothes_ids.size(0), clothes_ids.size(0))\n",
    "        clothes_corrects2.update(torch.sum(preds4 == clothes_ids.data).float()/clothes_ids.size(0), clothes_ids.size(0))\n",
    "        batch_cla_loss.update(cla_loss.item(), pids.size(0))\n",
    "        batch_pair_loss.update(pair_loss.item(), pids.size(0))\n",
    "        batch_clo_loss.update(clothes_loss.item(), clothes_ids.size(0))\n",
    "        batch_adv_loss.update(adv_loss.item(), clothes_ids.size(0))\n",
    "        batch_loss2.update(loss2.item(), clothes_ids.size(0))\n",
    "        batch_clothes_loss2.update(clothes_loss2.item(), clothes_ids.size(0))\n",
    "        batch_jsd_loss.update(jsd_loss.item(), clothes_ids.size(0)) #`my\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "    logger.info('Epoch{0} '\n",
    "                  'Time:{batch_time.sum:.1f}s '\n",
    "                  'Data:{data_time.sum:.1f}s '\n",
    "                  'ClaLoss:{cla_loss.avg:.4f} '\n",
    "                  'PairLoss:{pair_loss.avg:.4f} '\n",
    "                  'CloLoss:{clo_loss.avg:.4f} '\n",
    "                  'AdvLoss:{adv_loss.avg:.4f} '\n",
    "                  'clothes_loss2:{clothes_loss2.avg:.4f} '\n",
    "                  'loss2:{loss2.avg:.4f} '\n",
    "                  'jsd_loss:{jsd_loss.avg: .4f}' \n",
    "                  'Acc:{acc.avg:.2%} '\n",
    "                  'Acc2:{acc2.avg:.2%} '\n",
    "                  'Acc3:{acc3.avg:.2%} '\n",
    "                  'CloAcc:{clo_acc.avg:.2%} '\n",
    "                  'Clo2Acc:{clo2_acc.avg:.2%} '.format(\n",
    "                   epoch, batch_time=batch_time, data_time=data_time, \n",
    "                   cla_loss=batch_cla_loss, pair_loss=batch_pair_loss, \n",
    "                   clo_loss=batch_clo_loss, adv_loss=batch_adv_loss, \n",
    "                   clothes_loss2=batch_clothes_loss2, \n",
    "                   loss2=batch_loss2, jsd_loss=batch_jsd_loss,\n",
    "                   acc=corrects, acc2=corrects2, acc3=corrects3, \n",
    "                   clo_acc=clothes_corrects, clo2_acc=clothes_corrects2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
